{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "deprecated_version_of() got an unexpected keyword argument 'oldname'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\EBLab\\OneDrive - NVIDIA Corporation\\Desktop\\Bell\\.venv\\Lib\\site-packages\\moviepy\\editor.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVideoClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoClip, ImageClip, ColorClip, TextClip\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompositing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCompositeVideoClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompositeVideoClip, clips_array\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompositing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcatenate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concatenate_videoclips, concatenate \u001b[38;5;66;03m# concatenate=deprecated\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAudioClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioClip, CompositeAudioClip, concatenate_audioclips\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAudioFileClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioFileClip\n",
      "File \u001b[1;32mc:\\Users\\EBLab\\OneDrive - NVIDIA Corporation\\Desktop\\Bell\\.venv\\Lib\\site-packages\\moviepy\\video\\compositing\\concatenate.py:120\u001b[0m\n\u001b[0;32m    116\u001b[0m     result\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(fpss) \u001b[38;5;28;01mif\u001b[39;00m fpss \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 120\u001b[0m concatenate \u001b[38;5;241m=\u001b[39m \u001b[43mdeprecated_version_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcatenate_videoclips\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43moldname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcatenate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: deprecated_version_of() got an unexpected keyword argument 'oldname'"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import sys\n",
    "\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from typing import Sequence\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Optional\n",
    "import ai2thor.server\n",
    "from typing import Union\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "__version__ = \"<REPLACE_WITH_VERSION>\"\n",
    "__all__ = [\"plot_frames\", \"show_video\", \"start_xserver\", \"overlay\", \"side_by_side\"]\n",
    "\n",
    "\n",
    "def show_objects_table(objects: list) -> None:\n",
    "    \"\"\"Visualizes objects in a way that they are clickable and filterable.\n",
    "\n",
    "    Example:\n",
    "    event = controller.step(\"MoveAhead\")\n",
    "    objects = event.metadata[\"objects\"]\n",
    "    show_objects_table(objects)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from collections import OrderedDict\n",
    "    from google.colab.data_table import DataTable\n",
    "\n",
    "    processed_objects = []\n",
    "    for obj in objects:\n",
    "        obj = obj.copy()\n",
    "        obj[\"position[x]\"] = round(obj[\"position\"][\"x\"], 4)\n",
    "        obj[\"position[y]\"] = round(obj[\"position\"][\"y\"], 4)\n",
    "        obj[\"position[z]\"] = round(obj[\"position\"][\"z\"], 4)\n",
    "\n",
    "        obj[\"rotation[x]\"] = round(obj[\"rotation\"][\"x\"], 4)\n",
    "        obj[\"rotation[y]\"] = round(obj[\"rotation\"][\"y\"], 4)\n",
    "        obj[\"rotation[z]\"] = round(obj[\"rotation\"][\"z\"], 4)\n",
    "\n",
    "        del obj[\"position\"]\n",
    "        del obj[\"rotation\"]\n",
    "\n",
    "        # these are too long to display\n",
    "        del obj[\"objectOrientedBoundingBox\"]\n",
    "        del obj[\"axisAlignedBoundingBox\"]\n",
    "        del obj[\"receptacleObjectIds\"]\n",
    "\n",
    "        obj[\"mass\"] = round(obj[\"mass\"], 4)\n",
    "        obj[\"distance\"] = round(obj[\"distance\"], 4)\n",
    "\n",
    "        obj = OrderedDict(obj)\n",
    "        obj.move_to_end(\"distance\", last=False)\n",
    "        obj.move_to_end(\"rotation[z]\", last=False)\n",
    "        obj.move_to_end(\"rotation[y]\", last=False)\n",
    "        obj.move_to_end(\"rotation[x]\", last=False)\n",
    "\n",
    "        obj.move_to_end(\"position[z]\", last=False)\n",
    "        obj.move_to_end(\"position[y]\", last=False)\n",
    "        obj.move_to_end(\"position[x]\", last=False)\n",
    "\n",
    "        obj.move_to_end(\"name\", last=False)\n",
    "        obj.move_to_end(\"objectId\", last=False)\n",
    "        obj.move_to_end(\"objectType\", last=False)\n",
    "\n",
    "        processed_objects.append(obj)\n",
    "\n",
    "    df = pd.DataFrame(processed_objects)\n",
    "    print(\n",
    "        \"Object Metadata. Not showing objectOrientedBoundingBox, axisAlignedBoundingBox, and receptacleObjectIds for clarity.\"\n",
    "    )\n",
    "\n",
    "    return DataTable(df, max_columns=150, num_rows_per_page=150)\n",
    "\n",
    "\n",
    "def overlay(\n",
    "    frame1: np.ndarray,\n",
    "    frame2: np.ndarray,\n",
    "    title: Optional[str] = None,\n",
    "    frame2_alpha: float = 0.75,\n",
    ") -> None:\n",
    "    \"\"\"Blend image frame1 and frame2 on top of each other.\n",
    "\n",
    "    Example:\n",
    "    event1 = controller.last_event\n",
    "    event2 = controller.step(\"RotateRight\")\n",
    "    overlay(event1.frame, event2.frame)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, dpi=150, figsize=(4, 5))\n",
    "    if not (0 < frame2_alpha < 1):\n",
    "        raise ValueError(\"frame2_alpha must be in (0:1) not \" + frame2_alpha)\n",
    "\n",
    "    if frame1.dtype == np.uint8:\n",
    "        frame1 = frame1 / 255\n",
    "    if frame2.dtype == np.uint8:\n",
    "        frame2 = frame2 / 255\n",
    "\n",
    "    ax.imshow(frame2_alpha * frame2 + (1 - frame2_alpha) * frame1)\n",
    "    ax.axis(\"off\")\n",
    "    if title:\n",
    "        fig.suptitle(title, y=0.87, x=0.5125)\n",
    "\n",
    "\n",
    "def side_by_side(\n",
    "    frame1: np.ndarray, frame2: np.ndarray, title: Optional[str] = None\n",
    ") -> None:\n",
    "    \"\"\"Plot 2 image frames next to each other.\n",
    "\n",
    "    Example:\n",
    "    event1 = controller.last_event\n",
    "    event2 = controller.step(\"RotateRight\")\n",
    "    overlay(event1.frame, event2.frame)\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, dpi=150, figsize=(8, 5))\n",
    "    axs[0].imshow(frame1)\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(frame2)\n",
    "    axs[1].axis(\"off\")\n",
    "    if title:\n",
    "        fig.suptitle(title, y=0.85, x=0.5125)\n",
    "\n",
    "\n",
    "def plot_frames(event: Union[ai2thor.server.Event, np.ndarray]) -> None:\n",
    "    \"\"\"Visualize all the frames on an AI2-THOR Event.\n",
    "\n",
    "    Example:\n",
    "    plot_frames(controller.last_event)\n",
    "    \"\"\"\n",
    "    if isinstance(event, ai2thor.server.Event):\n",
    "        frames = dict()\n",
    "        third_person_frames = event.third_party_camera_frames\n",
    "        if event.frame is not None:\n",
    "            frames[\"RGB\"] = event.frame\n",
    "        if event.instance_segmentation_frame is not None:\n",
    "            frames[\"Instance Segmentation\"] = event.instance_segmentation_frame\n",
    "        if event.semantic_segmentation_frame is not None:\n",
    "            frames[\"Semantic Segmentation\"] = event.semantic_segmentation_frame\n",
    "        if event.normals_frame is not None:\n",
    "            frames[\"Normals\"] = event.normals_frame\n",
    "        if event.depth_frame is not None:\n",
    "            frames[\"Depth\"] = event.depth_frame\n",
    "\n",
    "        if len(frames) == 0:\n",
    "            raise Exception(\"No agent frames rendered on this event!\")\n",
    "\n",
    "        rows = 2 if len(third_person_frames) else 1\n",
    "        cols = max(len(frames), len(third_person_frames))\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=rows, ncols=cols, dpi=150, figsize=(3 * cols, 3 * rows)\n",
    "        )\n",
    "\n",
    "        agent_row = axs[0] if rows > 1 else axs\n",
    "\n",
    "        for i, (name, frame) in enumerate(frames.items()):\n",
    "            ax = agent_row[i] if cols > 1 else agent_row\n",
    "            im = ax.imshow(frame)\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(name)\n",
    "\n",
    "            if name == \"Depth\":\n",
    "                fig.colorbar(im, fraction=0.046, pad=0.04, ax=ax)\n",
    "\n",
    "        # set unused axes off\n",
    "        for i in range(len(frames), cols):\n",
    "            agent_row[i].axis(\"off\")\n",
    "\n",
    "        # add third party camera frames\n",
    "        if rows > 1:\n",
    "            for i, frame in enumerate(third_person_frames):\n",
    "                ax = axs[1][i] if cols > 1 else axs[1]\n",
    "                ax.imshow(frame)\n",
    "                ax.axis(\"off\")\n",
    "            for i in range(len(third_person_frames), cols):\n",
    "                axs[1][i].axis(\"off\")\n",
    "\n",
    "            fig.text(x=0.1, y=0.715, s=\"Agent Frames\", rotation=\"vertical\", va=\"center\")\n",
    "            fig.text(\n",
    "                x=0.1,\n",
    "                y=0.3025,\n",
    "                s=\"Third Person Frames\",\n",
    "                rotation=\"vertical\",\n",
    "                va=\"center\",\n",
    "            )\n",
    "    elif isinstance(event, np.ndarray):\n",
    "        return Image.fromarray(event)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Unknown type: {type(event)}. \"\n",
    "            \"Must be np.ndarray or ai2thor.server.Event.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def show_video(frames: Sequence[np.ndarray], fps: int = 10):\n",
    "    \"\"\"Show a video composed of a sequence of frames.\n",
    "\n",
    "    Example:\n",
    "    frames = [\n",
    "        controller.step(\"RotateRight\", degrees=5).frame\n",
    "        for _ in range(72)\n",
    "    ]\n",
    "    show_video(frames, fps=5)\n",
    "    \"\"\"\n",
    "    frames = ImageSequenceClip(frames, fps=fps)\n",
    "    return frames.ipython_display()\n",
    "\n",
    "\n",
    "def start_xserver() -> None:\n",
    "    \"\"\"Provide the ability to render AI2-THOR using Google Colab. \"\"\"\n",
    "    # Thanks to the [Unity ML Agents team](https://github.com/Unity-Technologies/ml-agents)\n",
    "    # for most of this setup! :)\n",
    "\n",
    "    def progress(value):\n",
    "        return HTML(\n",
    "            f\"\"\"\n",
    "            <progress value='{value}' max=\"100\", style='width: 100%'>\n",
    "                {value}\n",
    "            </progress>\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    progress_bar = display(progress(0), display_id=True)\n",
    "\n",
    "    try:\n",
    "        import google.colab\n",
    "\n",
    "        using_colab = True\n",
    "    except ImportError:\n",
    "        using_colab = False\n",
    "\n",
    "    if using_colab:\n",
    "        with open(\"frame-buffer\", \"w\") as writefile:\n",
    "            writefile.write(\n",
    "                \"\"\"#taken from https://gist.github.com/jterrace/2911875\n",
    "        XVFB=/usr/bin/Xvfb\n",
    "        XVFBARGS=\":1 -screen 0 1024x768x24 -ac +extension GLX +render -noreset\"\n",
    "        PIDFILE=./frame-buffer.pid\n",
    "        case \"$1\" in\n",
    "        start)\n",
    "            /sbin/start-stop-daemon --start --quiet --pidfile $PIDFILE --make-pidfile --background --exec $XVFB -- $XVFBARGS\n",
    "            ;;\n",
    "        stop)\n",
    "            /sbin/start-stop-daemon --stop --quiet --pidfile $PIDFILE\n",
    "            rm $PIDFILE\n",
    "            ;;\n",
    "        restart)\n",
    "            $0 stop\n",
    "            $0 start\n",
    "            ;;\n",
    "        *)\n",
    "                exit 1\n",
    "        esac\n",
    "        exit 0\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "        progress_bar.update(progress(5))\n",
    "        os.system(\"apt-get install daemon >/dev/null 2>&1\")\n",
    "\n",
    "        progress_bar.update(progress(10))\n",
    "        os.system(\"apt-get install wget >/dev/null 2>&1\")\n",
    "\n",
    "        progress_bar.update(progress(20))\n",
    "        os.system(\n",
    "            \"wget http://ai2thor.allenai.org/ai2thor-colab/libxfont1_1.5.1-1ubuntu0.16.04.4_amd64.deb >/dev/null 2>&1\"\n",
    "        )\n",
    "\n",
    "        progress_bar.update(progress(30))\n",
    "        os.system(\n",
    "            \"wget --output-document xvfb.deb http://ai2thor.allenai.org/ai2thor-colab/xvfb_1.18.4-0ubuntu0.12_amd64.deb >/dev/null 2>&1\"\n",
    "        )\n",
    "\n",
    "        progress_bar.update(progress(40))\n",
    "        os.system(\"dpkg -i libxfont1_1.5.1-1ubuntu0.16.04.4_amd64.deb >/dev/null 2>&1\")\n",
    "\n",
    "        progress_bar.update(progress(50))\n",
    "        os.system(\"dpkg -i xvfb.deb >/dev/null 2>&1\")\n",
    "\n",
    "        progress_bar.update(progress(70))\n",
    "        os.system(\"rm libxfont1_1.5.1-1ubuntu0.16.04.4_amd64.deb\")\n",
    "\n",
    "        progress_bar.update(progress(80))\n",
    "        os.system(\"rm xvfb.deb\")\n",
    "\n",
    "        progress_bar.update(progress(90))\n",
    "        os.system(\"bash frame-buffer start\")\n",
    "\n",
    "        os.environ[\"DISPLAY\"] = \":1\"\n",
    "    progress_bar.update(progress(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
